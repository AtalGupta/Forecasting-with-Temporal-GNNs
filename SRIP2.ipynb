{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "from torch_geometric_temporal.nn.recurrent import EvolveGCNH, EvolveGCNO, GConvLSTM, GConvGRU\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prcp1</th>\n",
       "      <th>SM1</th>\n",
       "      <th>Prcp2</th>\n",
       "      <th>SM2</th>\n",
       "      <th>Prcp3</th>\n",
       "      <th>SM3</th>\n",
       "      <th>flood1</th>\n",
       "      <th>flood2</th>\n",
       "      <th>flood3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.539606</td>\n",
       "      <td>0.590441</td>\n",
       "      <td>2.511432</td>\n",
       "      <td>0.474052</td>\n",
       "      <td>4.585283</td>\n",
       "      <td>0.484656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.274125</td>\n",
       "      <td>1.249220</td>\n",
       "      <td>7.461011</td>\n",
       "      <td>2.159259</td>\n",
       "      <td>17.690303</td>\n",
       "      <td>3.474562</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000114</td>\n",
       "      <td>0.106579</td>\n",
       "      <td>1.842560</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>3.395878</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.360013</td>\n",
       "      <td>0.429366</td>\n",
       "      <td>2.085287</td>\n",
       "      <td>0.212607</td>\n",
       "      <td>3.610686</td>\n",
       "      <td>0.137334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.158710</td>\n",
       "      <td>0.248820</td>\n",
       "      <td>1.282190</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.592812</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1.357030</td>\n",
       "      <td>0.426691</td>\n",
       "      <td>2.020841</td>\n",
       "      <td>0.197245</td>\n",
       "      <td>3.431358</td>\n",
       "      <td>0.103488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1.154324</td>\n",
       "      <td>0.244887</td>\n",
       "      <td>3.097722</td>\n",
       "      <td>0.201381</td>\n",
       "      <td>6.761527</td>\n",
       "      <td>0.473908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>3.315756</td>\n",
       "      <td>2.183443</td>\n",
       "      <td>2.927501</td>\n",
       "      <td>2.330118</td>\n",
       "      <td>3.422077</td>\n",
       "      <td>2.060617</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1.779925</td>\n",
       "      <td>0.805979</td>\n",
       "      <td>2.532323</td>\n",
       "      <td>0.718383</td>\n",
       "      <td>4.327215</td>\n",
       "      <td>0.680561</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>4.678548</td>\n",
       "      <td>3.405710</td>\n",
       "      <td>6.994089</td>\n",
       "      <td>4.473998</td>\n",
       "      <td>13.186105</td>\n",
       "      <td>5.103808</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Prcp1       SM1     Prcp2       SM2      Prcp3       SM3  flood1  \\\n",
       "0    1.539606  0.590441  2.511432  0.474052   4.585283  0.484656       0   \n",
       "1    2.274125  1.249220  7.461011  2.159259  17.690303  3.474562       1   \n",
       "2    1.000114  0.106579  1.842560  0.010000   3.395878  0.010000       0   \n",
       "3    1.360013  0.429366  2.085287  0.212607   3.610686  0.137334       0   \n",
       "4    1.158710  0.248820  1.282190  0.010000   1.592812  0.010000       0   \n",
       "..        ...       ...       ...       ...        ...       ...     ...   \n",
       "360  1.357030  0.426691  2.020841  0.197245   3.431358  0.103488       0   \n",
       "361  1.154324  0.244887  3.097722  0.201381   6.761527  0.473908       0   \n",
       "362  3.315756  2.183443  2.927501  2.330118   3.422077  2.060617       1   \n",
       "363  1.779925  0.805979  2.532323  0.718383   4.327215  0.680561       0   \n",
       "364  4.678548  3.405710  6.994089  4.473998  13.186105  5.103808       1   \n",
       "\n",
       "     flood2  flood3  \n",
       "0         0       0  \n",
       "1         1       1  \n",
       "2         0       0  \n",
       "3         0       0  \n",
       "4         0       0  \n",
       "..      ...     ...  \n",
       "360       0       0  \n",
       "361       0       1  \n",
       "362       1       0  \n",
       "363       0       0  \n",
       "364       1       1  \n",
       "\n",
       "[365 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_data_df = pd.read_csv(\"datasetsrip - synthetic-prcp-SM-flood-data-v1.csv.csv\")\n",
    "syn_data_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "syn_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Layer GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Loss = 1.3124\n",
      "Epoch 2/10: Loss = 0.6467\n",
      "Epoch 3/10: Loss = 0.4631\n",
      "Epoch 4/10: Loss = 0.3925\n",
      "Epoch 5/10: Loss = 0.3635\n",
      "Epoch 6/10: Loss = 0.3267\n",
      "Epoch 7/10: Loss = 0.3055\n",
      "Epoch 8/10: Loss = 0.2791\n",
      "Epoch 9/10: Loss = 0.2669\n",
      "Epoch 10/10: Loss = 0.2381\n",
      "Test Accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "def test_2layer_GCN(df, window = 3):\n",
    "    df_list = [df[i:i+window] for i in range(0,df.shape[0]-window+1,1)]\n",
    "\n",
    "    df_dict = {}\n",
    "    df_dict['x'] = [df_list[i].iloc[:,0:6] for i in range(len(df_list))]\n",
    "    df_dict['y'] = [df_list[i].iloc[-1,-3:] for i in range(len(df_list))]\n",
    "\n",
    "    \n",
    "    def create_node_features(df_x):\n",
    "        Prcp1 = df_x['Prcp1'].values\n",
    "        Prcp2 = df_x['Prcp2'].values\n",
    "        Prcp3 = df_x['Prcp3'].values\n",
    "        SM1 = df_x['SM1'].values\n",
    "        SM2 = df_x['SM2'].values\n",
    "        SM3 = df_x['SM3'].values\n",
    "        # Stack Prcp and SM for each node\n",
    "        node_1 = np.hstack((Prcp1, SM1))\n",
    "        node_2 = np.hstack((Prcp2, SM2))\n",
    "        node_3 = np.hstack((Prcp3, SM3))\n",
    "        node_features = np.vstack((node_1, node_2, node_3))\n",
    "        \n",
    "        return node_features\n",
    "\n",
    "    data_list = []\n",
    "    for i in range(len(df_dict['x'])):\n",
    "        data_list.append(Data(\n",
    "            x=torch.tensor(create_node_features(df_dict['x'][i]), dtype=torch.float), \n",
    "            y=torch.tensor(df_dict['y'][i].values, dtype=torch.float), \n",
    "            edge_index=torch.tensor([[0,2], [1,1]], dtype=torch.long)\n",
    "            ))\n",
    "        \n",
    "    class GCN(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super(GCN, self).__init__()\n",
    "            self.conv1 = GCNConv(in_channels, 16)  \n",
    "            self.conv2 = GCNConv(16, out_channels)\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = torch.relu(x)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GCN(in_channels=2*window, out_channels=1).to(device)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    train_ratio = 0.75 \n",
    "    train_size = int(train_ratio * len(data_list))\n",
    "    train_data = data_list[:train_size]\n",
    "    test_data = data_list[train_size:]\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index).squeeze()\n",
    "            loss = criterion(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}: Loss = {total_loss / len(train_loader.dataset):.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index).squeeze()\n",
    "            predicted_labels = (out > 0.5).long()\n",
    "            correct += (predicted_labels == data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_2layer_GCN(syn_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EvolveGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.55226\n",
      "Epoch: 001, Loss: 0.52784\n",
      "Epoch: 002, Loss: 0.51323\n",
      "Epoch: 003, Loss: 0.50421\n",
      "Epoch: 004, Loss: 0.49555\n",
      "Epoch: 005, Loss: 0.46541\n",
      "Epoch: 006, Loss: 0.44751\n",
      "Epoch: 007, Loss: 0.43158\n",
      "Epoch: 008, Loss: 0.41556\n",
      "Epoch: 009, Loss: 0.39790\n",
      "Epoch: 010, Loss: 0.38182\n",
      "Epoch: 011, Loss: 0.29999\n",
      "Epoch: 012, Loss: 0.27044\n",
      "Epoch: 013, Loss: 0.25071\n",
      "Epoch: 014, Loss: 0.23114\n",
      "Epoch: 015, Loss: 0.21194\n",
      "Epoch: 016, Loss: 0.19350\n",
      "Epoch: 017, Loss: 0.17608\n",
      "Epoch: 018, Loss: 0.15995\n",
      "Epoch: 019, Loss: 0.14563\n",
      "Test Accuracy: 0.8804\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_EvolveGCNH(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0,2], [1, 1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0, 1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.75)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, node_count, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = EvolveGCNH(node_count, dim_in)\n",
    "            self.linear = Linear(dim_in, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x = self.recurrent(x, edge_index, edge_weight).relu()\n",
    "            x = self.linear(x)\n",
    "            return torch.sigmoid(x)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  \n",
    "    print(device)\n",
    "    model = TemporalGNN(node_count=3, dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(20):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_EvolveGCNH(syn_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.57825\n",
      "Epoch: 001, Loss: 0.53708\n",
      "Epoch: 002, Loss: 0.52942\n",
      "Epoch: 003, Loss: 0.52800\n",
      "Epoch: 004, Loss: 0.52775\n",
      "Epoch: 005, Loss: 0.52773\n",
      "Epoch: 006, Loss: 0.52774\n",
      "Epoch: 007, Loss: 0.52775\n",
      "Epoch: 008, Loss: 0.52776\n",
      "Epoch: 009, Loss: 0.52776\n",
      "Epoch: 010, Loss: 0.52777\n",
      "Epoch: 011, Loss: 0.52777\n",
      "Epoch: 012, Loss: 0.52777\n",
      "Epoch: 013, Loss: 0.52778\n",
      "Epoch: 014, Loss: 0.52778\n",
      "Epoch: 015, Loss: 0.52778\n",
      "Epoch: 016, Loss: 0.52778\n",
      "Epoch: 017, Loss: 0.52778\n",
      "Epoch: 018, Loss: 0.52778\n",
      "Epoch: 019, Loss: 0.52778\n",
      "Test Accuracy: 0.5906\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_EvolveGCNO(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0,2], [1,1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0,1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.75)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = EvolveGCNO(dim_in)\n",
    "            self.linear = Linear(dim_in, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x = self.recurrent(x, edge_index, edge_weight).relu()\n",
    "            x = self.linear(x)\n",
    "            return torch.sigmoid(x)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  \n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(20):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_EvolveGCNO(syn_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Layer RNN -> 1-Layer GCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aatal\\anaconda3\\envs\\snakes\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Loss = 0.6120\n",
      "Epoch 2/10: Loss = 0.5056\n",
      "Epoch 3/10: Loss = 0.4233\n",
      "Epoch 4/10: Loss = 0.3656\n",
      "Epoch 5/10: Loss = 0.3155\n",
      "Epoch 6/10: Loss = 0.2745\n",
      "Epoch 7/10: Loss = 0.2498\n",
      "Epoch 8/10: Loss = 0.2274\n",
      "Epoch 9/10: Loss = 0.2124\n",
      "Epoch 10/10: Loss = 0.1990\n",
      "Test Accuracy: 0.9267\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_RNN_2layer_GCN(df, window = 3):\n",
    "    df_list = [df[i:i+window] for i in range(0,df.shape[0]-window+1,1)]\n",
    "\n",
    "    df_dict = {}\n",
    "    df_dict['x'] = [df_list[i].iloc[:,0:6] for i in range(len(df_list))]\n",
    "    df_dict['y'] = [df_list[i].iloc[-1,-3:] for i in range(len(df_list))]\n",
    "\n",
    "    \n",
    "    def create_node_features(df_x):\n",
    "        Prcp1 = df_x['Prcp1'].values\n",
    "        Prcp2 = df_x['Prcp2'].values\n",
    "        Prcp3 = df_x['Prcp3'].values\n",
    "        SM1 = df_x['SM1'].values\n",
    "        SM2 = df_x['SM2'].values\n",
    "        SM3 = df_x['SM3'].values\n",
    "        node_1 = np.hstack((Prcp1, SM1))\n",
    "        node_2 = np.hstack((Prcp2, SM2))\n",
    "        node_3 = np.hstack((Prcp3, SM3))\n",
    "        node_features = np.vstack((node_1, node_2, node_3))\n",
    "        return node_features\n",
    "\n",
    "    data_list = []\n",
    "    for i in range(len(df_dict['x'])):\n",
    "        data_list.append(Data(\n",
    "            x=torch.tensor(create_node_features(df_dict['x'][i]), dtype=torch.float), \n",
    "            y=torch.tensor(df_dict['y'][i].values, dtype=torch.float),\n",
    "            edge_index=torch.tensor([[0,2], [1,1]], dtype=torch.long) \n",
    "            ))\n",
    "        \n",
    "    class RNN_GCN(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super(RNN_GCN, self).__init__()\n",
    "            self.rnn = nn.RNN(input_size=in_channels, hidden_size=16, num_layers=1, batch_first=True)\n",
    "            \n",
    "            self.conv2 = GCNConv(16, out_channels)\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x, h = self.rnn(x)\n",
    "            x = torch.relu(x)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "        \n",
    "        \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = RNN_GCN(in_channels=2*window, out_channels=1).to(device)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    train_ratio = 0.75  \n",
    "    train_size = int(train_ratio * len(data_list))\n",
    "    train_data = data_list[:train_size]\n",
    "    test_data = data_list[train_size:]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index).squeeze()\n",
    "            loss = criterion(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}: Loss = {total_loss / len(train_loader.dataset):.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index).squeeze()\n",
    "            predicted_labels = (out > 0.5).long()\n",
    "            correct += (predicted_labels == data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_RNN_2layer_GCN(syn_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Layer GCN -> 1-Layer RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Loss = 0.6331\n",
      "Epoch 2/10: Loss = 0.4836\n",
      "Epoch 3/10: Loss = 0.3810\n",
      "Epoch 4/10: Loss = 0.3237\n",
      "Epoch 5/10: Loss = 0.2884\n",
      "Epoch 6/10: Loss = 0.2488\n",
      "Epoch 7/10: Loss = 0.2261\n",
      "Epoch 8/10: Loss = 0.1993\n",
      "Epoch 9/10: Loss = 0.1848\n",
      "Epoch 10/10: Loss = 0.1726\n",
      "Test Accuracy: 0.9121\n"
     ]
    }
   ],
   "source": [
    "def test_2layer_GCN_1layer_RNN(df, window = 3):\n",
    "    df_list = [df[i:i+window] for i in range(0,df.shape[0]-window+1,1)]\n",
    "\n",
    "    df_dict = {}\n",
    "    df_dict['x'] = [df_list[i].iloc[:,0:6] for i in range(len(df_list))]\n",
    "    df_dict['y'] = [df_list[i].iloc[-1,-3:] for i in range(len(df_list))]\n",
    "\n",
    "    \n",
    "    def create_node_features(df_x):\n",
    "        Prcp1 = df_x['Prcp1'].values\n",
    "        Prcp2 = df_x['Prcp2'].values\n",
    "        Prcp3 = df_x['Prcp3'].values\n",
    "        SM1 = df_x['SM1'].values\n",
    "        SM2 = df_x['SM2'].values\n",
    "        SM3 = df_x['SM3'].values\n",
    "        node_1 = np.hstack((Prcp1, SM1))\n",
    "        node_2 = np.hstack((Prcp2, SM2))\n",
    "        node_3 = np.hstack((Prcp3, SM3))\n",
    "        node_features = np.vstack((node_1, node_2, node_3))\n",
    "        return node_features\n",
    "\n",
    "    data_list = []\n",
    "    for i in range(len(df_dict['x'])):\n",
    "        data_list.append(Data(\n",
    "            x=torch.tensor(create_node_features(df_dict['x'][i]), dtype=torch.float),\n",
    "            y=torch.tensor(df_dict['y'][i].values, dtype=torch.float), \n",
    "            edge_index=torch.tensor([[0,2], [1,1]], dtype=torch.long) \n",
    "            ))\n",
    "        \n",
    "    class GCN_RNN(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super(GCN_RNN, self).__init__()\n",
    "            self.conv1 = GCNConv(in_channels, 16)  \n",
    "            self.rnn = nn.RNN(input_size=16, hidden_size=16, num_layers=1, batch_first=True)\n",
    "            self.linear = nn.Linear(16, out_channels)\n",
    "        \n",
    "        def forward(self, x, edge_index):\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = torch.relu(x)\n",
    "            x, h = self.rnn(x)\n",
    "            x = torch.relu(x)\n",
    "            x = self.linear(x)\n",
    "            return torch.sigmoid(x)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GCN_RNN(in_channels=2*window, out_channels=1).to(device)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    train_ratio = 0.75\n",
    "    train_size = int(train_ratio * len(data_list))\n",
    "    train_data = data_list[:train_size]\n",
    "    test_data = data_list[train_size:]\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index).squeeze()\n",
    "            loss = criterion(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}: Loss = {total_loss / len(train_loader.dataset):.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index).squeeze()\n",
    "            predicted_labels = (out > 0.5).long()\n",
    "            correct += (predicted_labels == data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_2layer_GCN_1layer_RNN(syn_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GConvGRU & GConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.44646\n",
      "Epoch: 001, Loss: 0.25824\n",
      "Epoch: 002, Loss: 0.22243\n",
      "Epoch: 003, Loss: 0.33058\n",
      "Epoch: 004, Loss: 0.21400\n",
      "Epoch: 005, Loss: 0.18101\n",
      "Epoch: 006, Loss: 0.15226\n",
      "Epoch: 007, Loss: 0.16020\n",
      "Epoch: 008, Loss: 0.15111\n",
      "Epoch: 009, Loss: 0.19102\n",
      "Test Accuracy: 0.9239\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_GConvGRU(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0,2], [1,1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0,1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.75)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = GConvGRU(dim_in, 16, 1)\n",
    "            self.linear = Linear(16, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x = self.recurrent(x, edge_index, edge_weight).relu()\n",
    "            x = self.linear(x)\n",
    "            return torch.sigmoid(x)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    " \n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_GConvGRU(syn_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.64018\n",
      "Epoch: 001, Loss: 0.32906\n",
      "Epoch: 002, Loss: 0.20860\n",
      "Epoch: 003, Loss: 0.15664\n",
      "Epoch: 004, Loss: 0.13061\n",
      "Epoch: 005, Loss: 0.11626\n",
      "Epoch: 006, Loss: 0.10767\n",
      "Epoch: 007, Loss: 0.10172\n",
      "Epoch: 008, Loss: 0.09704\n",
      "Epoch: 009, Loss: 0.09309\n",
      "Test Accuracy: 0.9178\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_GConvLSTM(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0, 2], [1, 1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0, 1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = GConvLSTM(dim_in, 16, 1)\n",
    "            self.linear = Linear(16, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x, _ = self.recurrent(x, edge_index, edge_weight)\n",
    "            x = x.relu()\n",
    "            x = self.linear(x)\n",
    "            return x.sigmoid()\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_GConvLSTM(syn_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
