{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e447abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import dataloader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "from torch_geometric_temporal.nn.recurrent import GConvLSTM, GConvGRU\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a4053ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prcp1</th>\n",
       "      <th>SM1</th>\n",
       "      <th>Prcp2</th>\n",
       "      <th>SM2</th>\n",
       "      <th>Prcp3</th>\n",
       "      <th>SM3</th>\n",
       "      <th>flood1</th>\n",
       "      <th>flood2</th>\n",
       "      <th>flood3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.539606</td>\n",
       "      <td>0.590441</td>\n",
       "      <td>2.511432</td>\n",
       "      <td>0.474052</td>\n",
       "      <td>4.585283</td>\n",
       "      <td>0.484656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.274125</td>\n",
       "      <td>1.249220</td>\n",
       "      <td>7.461011</td>\n",
       "      <td>2.159259</td>\n",
       "      <td>17.690303</td>\n",
       "      <td>3.474562</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000114</td>\n",
       "      <td>0.106579</td>\n",
       "      <td>1.842560</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>3.395878</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.360013</td>\n",
       "      <td>0.429366</td>\n",
       "      <td>2.085287</td>\n",
       "      <td>0.212607</td>\n",
       "      <td>3.610686</td>\n",
       "      <td>0.137334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.158710</td>\n",
       "      <td>0.248820</td>\n",
       "      <td>1.282190</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.592812</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1.357030</td>\n",
       "      <td>0.426691</td>\n",
       "      <td>2.020841</td>\n",
       "      <td>0.197245</td>\n",
       "      <td>3.431358</td>\n",
       "      <td>0.103488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1.154324</td>\n",
       "      <td>0.244887</td>\n",
       "      <td>3.097722</td>\n",
       "      <td>0.201381</td>\n",
       "      <td>6.761527</td>\n",
       "      <td>0.473908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>3.315756</td>\n",
       "      <td>2.183443</td>\n",
       "      <td>2.927501</td>\n",
       "      <td>2.330118</td>\n",
       "      <td>3.422077</td>\n",
       "      <td>2.060617</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1.779925</td>\n",
       "      <td>0.805979</td>\n",
       "      <td>2.532323</td>\n",
       "      <td>0.718383</td>\n",
       "      <td>4.327215</td>\n",
       "      <td>0.680561</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>4.678548</td>\n",
       "      <td>3.405710</td>\n",
       "      <td>6.994089</td>\n",
       "      <td>4.473998</td>\n",
       "      <td>13.186105</td>\n",
       "      <td>5.103808</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Prcp1       SM1     Prcp2       SM2      Prcp3       SM3  flood1  \\\n",
       "0    1.539606  0.590441  2.511432  0.474052   4.585283  0.484656       0   \n",
       "1    2.274125  1.249220  7.461011  2.159259  17.690303  3.474562       1   \n",
       "2    1.000114  0.106579  1.842560  0.010000   3.395878  0.010000       0   \n",
       "3    1.360013  0.429366  2.085287  0.212607   3.610686  0.137334       0   \n",
       "4    1.158710  0.248820  1.282190  0.010000   1.592812  0.010000       0   \n",
       "..        ...       ...       ...       ...        ...       ...     ...   \n",
       "360  1.357030  0.426691  2.020841  0.197245   3.431358  0.103488       0   \n",
       "361  1.154324  0.244887  3.097722  0.201381   6.761527  0.473908       0   \n",
       "362  3.315756  2.183443  2.927501  2.330118   3.422077  2.060617       1   \n",
       "363  1.779925  0.805979  2.532323  0.718383   4.327215  0.680561       0   \n",
       "364  4.678548  3.405710  6.994089  4.473998  13.186105  5.103808       1   \n",
       "\n",
       "     flood2  flood3  \n",
       "0         0       0  \n",
       "1         1       1  \n",
       "2         0       0  \n",
       "3         0       0  \n",
       "4         0       0  \n",
       "..      ...     ...  \n",
       "360       0       0  \n",
       "361       0       1  \n",
       "362       1       0  \n",
       "363       0       0  \n",
       "364       1       1  \n",
       "\n",
       "[365 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"datasetsrip - synthetic-prcp-SM-flood-data-v1.csv.csv\")\n",
    "data_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b15819e",
   "metadata": {},
   "source": [
    "GConvGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2413cd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.38113\n",
      "Epoch: 001, Loss: 0.25151\n",
      "Epoch: 002, Loss: 0.20746\n",
      "Epoch: 003, Loss: 0.18814\n",
      "Epoch: 004, Loss: 0.17641\n",
      "Epoch: 005, Loss: 0.16776\n",
      "Epoch: 006, Loss: 0.16098\n",
      "Epoch: 007, Loss: 0.15548\n",
      "Epoch: 008, Loss: 0.15102\n",
      "Epoch: 009, Loss: 0.14720\n",
      "Test Accuracy: 0.9239\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_GConvGRU(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0,2], [1,1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0,1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.75)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = GConvGRU(dim_in, 16, 1)\n",
    "            self.linear = Linear(16, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x = self.recurrent(x, edge_index, edge_weight).relu()\n",
    "            x = self.linear(x)\n",
    "            return torch.sigmoid(x)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    " \n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_GConvGRU(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdcc8f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.38139\n",
      "Epoch: 001, Loss: 0.26604\n",
      "Epoch: 002, Loss: 0.23100\n",
      "Epoch: 003, Loss: 0.21486\n",
      "Epoch: 004, Loss: 0.20595\n",
      "Epoch: 005, Loss: 0.20018\n",
      "Epoch: 006, Loss: 0.19630\n",
      "Epoch: 007, Loss: 0.19520\n",
      "Epoch: 008, Loss: 0.19336\n",
      "Epoch: 009, Loss: 0.19135\n",
      "Epoch: 010, Loss: 0.18936\n",
      "Epoch: 011, Loss: 0.18495\n",
      "Epoch: 012, Loss: 0.18197\n",
      "Epoch: 013, Loss: 0.17803\n",
      "Epoch: 014, Loss: 0.17585\n",
      "Epoch: 015, Loss: 0.17372\n",
      "Epoch: 016, Loss: 0.17672\n",
      "Epoch: 017, Loss: 0.17499\n",
      "Epoch: 018, Loss: 0.17343\n",
      "Epoch: 019, Loss: 0.17322\n",
      "Test Accuracy: 0.9203\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_GConvGRU(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0,2], [1,1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0,1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.75)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = GConvGRU(dim_in, 16, 1)\n",
    "            self.linear = Linear(16, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x = self.recurrent(x, edge_index, edge_weight).relu()\n",
    "            x = self.linear(x)\n",
    "            return torch.sigmoid(x)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    " \n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(20):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_GConvGRU(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c2e8252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.37592\n",
      "Epoch: 001, Loss: 0.27273\n",
      "Epoch: 002, Loss: 0.23945\n",
      "Epoch: 003, Loss: 0.22304\n",
      "Epoch: 004, Loss: 0.21306\n",
      "Epoch: 005, Loss: 0.20626\n",
      "Epoch: 006, Loss: 0.20058\n",
      "Epoch: 007, Loss: 0.19658\n",
      "Epoch: 008, Loss: 0.19345\n",
      "Epoch: 009, Loss: 0.19061\n",
      "Epoch: 010, Loss: 0.18528\n",
      "Epoch: 011, Loss: 0.18269\n",
      "Epoch: 012, Loss: 0.18025\n",
      "Epoch: 013, Loss: 0.17555\n",
      "Epoch: 014, Loss: 0.17831\n",
      "Epoch: 015, Loss: 0.17494\n",
      "Epoch: 016, Loss: 0.17590\n",
      "Epoch: 017, Loss: 0.17199\n",
      "Epoch: 018, Loss: 0.16869\n",
      "Epoch: 019, Loss: 0.17081\n",
      "Epoch: 020, Loss: 0.16592\n",
      "Epoch: 021, Loss: 0.16627\n",
      "Epoch: 022, Loss: 0.16374\n",
      "Epoch: 023, Loss: 0.16316\n",
      "Epoch: 024, Loss: 0.16355\n",
      "Epoch: 025, Loss: 0.16126\n",
      "Epoch: 026, Loss: 0.16031\n",
      "Epoch: 027, Loss: 0.15885\n",
      "Epoch: 028, Loss: 0.15768\n",
      "Epoch: 029, Loss: 0.15589\n",
      "Epoch: 030, Loss: 0.15430\n",
      "Epoch: 031, Loss: 0.15224\n",
      "Epoch: 032, Loss: 0.15048\n",
      "Epoch: 033, Loss: 0.14830\n",
      "Epoch: 034, Loss: 0.14615\n",
      "Epoch: 035, Loss: 0.14385\n",
      "Epoch: 036, Loss: 0.14123\n",
      "Epoch: 037, Loss: 0.13907\n",
      "Epoch: 038, Loss: 0.13667\n",
      "Epoch: 039, Loss: 0.13500\n",
      "Epoch: 040, Loss: 0.13238\n",
      "Epoch: 041, Loss: 0.12948\n",
      "Epoch: 042, Loss: 0.12597\n",
      "Epoch: 043, Loss: 0.12318\n",
      "Epoch: 044, Loss: 0.12022\n",
      "Epoch: 045, Loss: 0.11732\n",
      "Epoch: 046, Loss: 0.11600\n",
      "Epoch: 047, Loss: 0.11527\n",
      "Epoch: 048, Loss: 0.10968\n",
      "Epoch: 049, Loss: 0.10951\n",
      "Test Accuracy: 0.9312\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_GConvGRU(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0,2], [1,1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0,1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.75)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = GConvGRU(dim_in, 16, 1)\n",
    "            self.linear = Linear(16, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x = self.recurrent(x, edge_index, edge_weight).relu()\n",
    "            x = self.linear(x)\n",
    "            return torch.sigmoid(x)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    " \n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(50):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_GConvGRU(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "588719f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.36342\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m model\n\u001b[0;32m     67\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m---> 69\u001b[0m \u001b[43mtest_1layer_GConvGRU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 50\u001b[0m, in \u001b[0;36mtest_1layer_GConvGRU\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     48\u001b[0m     cost \u001b[38;5;241m=\u001b[39m criterion(y_hat, snapshot\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     49\u001b[0m     cost\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 50\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, cost\u001b[38;5;241m.\u001b[39mitem()))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\snakes\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\snakes\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\snakes\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\snakes\\lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\snakes\\lib\\site-packages\\torch\\optim\\adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    389\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    393\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_1layer_GConvGRU(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0,2], [1,1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0,1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.75)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = GConvGRU(dim_in, 16, 1)\n",
    "            self.linear = Linear(16, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x = self.recurrent(x, edge_index, edge_weight).relu()\n",
    "            x = self.linear(x)\n",
    "            return torch.sigmoid(x)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    " \n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(100):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_GConvGRU(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16fac8d",
   "metadata": {},
   "source": [
    "GConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3c3994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.39815\n",
      "Epoch: 001, Loss: 0.17005\n",
      "Epoch: 002, Loss: 0.11025\n",
      "Epoch: 003, Loss: 0.09311\n",
      "Epoch: 004, Loss: 0.08660\n",
      "Epoch: 005, Loss: 0.08353\n",
      "Epoch: 006, Loss: 0.08192\n",
      "Epoch: 007, Loss: 0.08101\n",
      "Epoch: 008, Loss: 0.08057\n",
      "Epoch: 009, Loss: 0.08030\n",
      "Test Accuracy: 0.9178\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_GConvLSTM(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0, 2], [1, 1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0, 1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = GConvLSTM(dim_in, 16, 1)\n",
    "            self.linear = Linear(16, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x, _ = self.recurrent(x, edge_index, edge_weight)\n",
    "            x = x.relu()\n",
    "            x = self.linear(x)\n",
    "            return x.sigmoid()\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_GConvLSTM(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7902cea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.21905\n",
      "Epoch: 001, Loss: 0.11648\n",
      "Epoch: 002, Loss: 0.08965\n",
      "Epoch: 003, Loss: 0.09675\n",
      "Epoch: 004, Loss: 0.10131\n",
      "Epoch: 005, Loss: 0.09003\n",
      "Epoch: 006, Loss: 0.09843\n",
      "Epoch: 007, Loss: 0.10392\n",
      "Epoch: 008, Loss: 0.10088\n",
      "Epoch: 009, Loss: 0.10736\n",
      "Epoch: 010, Loss: 0.11733\n",
      "Epoch: 011, Loss: 0.12307\n",
      "Epoch: 012, Loss: 0.13162\n",
      "Epoch: 013, Loss: 0.11832\n",
      "Epoch: 014, Loss: 0.11951\n",
      "Epoch: 015, Loss: 0.11382\n",
      "Epoch: 016, Loss: 0.12555\n",
      "Epoch: 017, Loss: 0.12050\n",
      "Epoch: 018, Loss: 0.09819\n",
      "Epoch: 019, Loss: 0.12323\n",
      "Test Accuracy: 0.9315\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_GConvLSTM(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0, 2], [1, 1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0, 1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = GConvLSTM(dim_in, 16, 1)\n",
    "            self.linear = Linear(16, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x, _ = self.recurrent(x, edge_index, edge_weight)\n",
    "            x = x.relu()\n",
    "            x = self.linear(x)\n",
    "            return x.sigmoid()\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(20):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_GConvLSTM(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56ea2379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.16664\n",
      "Epoch: 001, Loss: 0.09381\n",
      "Epoch: 002, Loss: 0.09427\n",
      "Epoch: 003, Loss: 0.09333\n",
      "Epoch: 004, Loss: 0.08614\n",
      "Epoch: 005, Loss: 0.09777\n",
      "Epoch: 006, Loss: 0.09578\n",
      "Epoch: 007, Loss: 0.10823\n",
      "Epoch: 008, Loss: 0.11386\n",
      "Epoch: 009, Loss: 0.12289\n",
      "Epoch: 010, Loss: 0.11846\n",
      "Epoch: 011, Loss: 0.12164\n",
      "Epoch: 012, Loss: 0.12467\n",
      "Epoch: 013, Loss: 0.12719\n",
      "Epoch: 014, Loss: 0.12878\n",
      "Epoch: 015, Loss: 0.13060\n",
      "Epoch: 016, Loss: 0.12836\n",
      "Epoch: 017, Loss: 0.14596\n",
      "Epoch: 018, Loss: 0.14092\n",
      "Epoch: 019, Loss: 0.13220\n",
      "Epoch: 020, Loss: 0.14047\n",
      "Epoch: 021, Loss: 0.14707\n",
      "Epoch: 022, Loss: 0.08691\n",
      "Epoch: 023, Loss: 0.14055\n",
      "Epoch: 024, Loss: 0.14856\n",
      "Epoch: 025, Loss: 0.15062\n",
      "Epoch: 026, Loss: 0.14166\n",
      "Epoch: 027, Loss: 0.14305\n",
      "Epoch: 028, Loss: 0.15228\n",
      "Epoch: 029, Loss: 0.14792\n",
      "Epoch: 030, Loss: 0.14359\n",
      "Epoch: 031, Loss: 0.13324\n",
      "Epoch: 032, Loss: 0.13283\n",
      "Epoch: 033, Loss: 0.15027\n",
      "Epoch: 034, Loss: 0.15526\n",
      "Epoch: 035, Loss: 0.14832\n",
      "Epoch: 036, Loss: 0.15670\n",
      "Epoch: 037, Loss: 0.15806\n",
      "Epoch: 038, Loss: 0.15947\n",
      "Epoch: 039, Loss: 0.15390\n",
      "Epoch: 040, Loss: 0.15827\n",
      "Epoch: 041, Loss: 0.15768\n",
      "Epoch: 042, Loss: 0.16161\n",
      "Epoch: 043, Loss: 0.16216\n",
      "Epoch: 044, Loss: 0.15782\n",
      "Epoch: 045, Loss: 0.15967\n",
      "Epoch: 046, Loss: 0.15997\n",
      "Epoch: 047, Loss: 0.16261\n",
      "Epoch: 048, Loss: 0.12798\n",
      "Epoch: 049, Loss: 0.16158\n",
      "Test Accuracy: 0.9269\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_GConvLSTM(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0, 2], [1, 1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0, 1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = GConvLSTM(dim_in, 16, 1)\n",
    "            self.linear = Linear(16, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x, _ = self.recurrent(x, edge_index, edge_weight)\n",
    "            x = x.relu()\n",
    "            x = self.linear(x)\n",
    "            return x.sigmoid()\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(50):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_GConvLSTM(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d67d954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 000, Loss: 0.21687\n",
      "Epoch: 001, Loss: 0.11354\n",
      "Epoch: 002, Loss: 0.10237\n",
      "Epoch: 003, Loss: 0.09295\n",
      "Epoch: 004, Loss: 0.09802\n",
      "Epoch: 005, Loss: 0.09756\n",
      "Epoch: 006, Loss: 0.09908\n",
      "Epoch: 007, Loss: 0.10209\n",
      "Epoch: 008, Loss: 0.10134\n",
      "Epoch: 009, Loss: 0.10405\n",
      "Epoch: 010, Loss: 0.10539\n",
      "Epoch: 011, Loss: 0.11359\n",
      "Epoch: 012, Loss: 0.10897\n",
      "Epoch: 013, Loss: 0.10230\n",
      "Epoch: 014, Loss: 0.05497\n",
      "Epoch: 015, Loss: 0.11593\n",
      "Epoch: 016, Loss: 0.11319\n",
      "Epoch: 017, Loss: 0.11324\n",
      "Epoch: 018, Loss: 0.11110\n",
      "Epoch: 019, Loss: 0.13328\n",
      "Epoch: 020, Loss: 0.13784\n",
      "Epoch: 021, Loss: 0.13428\n",
      "Epoch: 022, Loss: 0.14441\n",
      "Epoch: 023, Loss: 0.13970\n",
      "Epoch: 024, Loss: 0.14839\n",
      "Epoch: 025, Loss: 0.14961\n",
      "Epoch: 026, Loss: 0.15121\n",
      "Epoch: 027, Loss: 0.15225\n",
      "Epoch: 028, Loss: 0.15290\n",
      "Epoch: 029, Loss: 0.15374\n",
      "Epoch: 030, Loss: 0.15217\n",
      "Epoch: 031, Loss: 0.14188\n",
      "Epoch: 032, Loss: 0.15376\n",
      "Epoch: 033, Loss: 0.15477\n",
      "Epoch: 034, Loss: 0.15605\n",
      "Epoch: 035, Loss: 0.15709\n",
      "Epoch: 036, Loss: 0.15543\n",
      "Epoch: 037, Loss: 0.15482\n",
      "Epoch: 038, Loss: 0.15549\n",
      "Epoch: 039, Loss: 0.15570\n",
      "Epoch: 040, Loss: 0.15560\n",
      "Epoch: 041, Loss: 0.15530\n",
      "Epoch: 042, Loss: 0.15483\n",
      "Epoch: 043, Loss: 0.15962\n",
      "Epoch: 044, Loss: 0.15553\n",
      "Epoch: 045, Loss: 0.16048\n",
      "Epoch: 046, Loss: 0.16157\n",
      "Epoch: 047, Loss: 0.16225\n",
      "Epoch: 048, Loss: 0.16262\n",
      "Epoch: 049, Loss: 0.16376\n",
      "Epoch: 050, Loss: 0.16387\n",
      "Epoch: 051, Loss: 0.16399\n",
      "Epoch: 052, Loss: 0.16205\n",
      "Epoch: 053, Loss: 0.16092\n",
      "Epoch: 054, Loss: 0.16194\n",
      "Epoch: 055, Loss: 0.16211\n",
      "Epoch: 056, Loss: 0.16216\n",
      "Epoch: 057, Loss: 0.16209\n",
      "Epoch: 058, Loss: 0.16195\n",
      "Epoch: 059, Loss: 0.16222\n",
      "Epoch: 060, Loss: 0.16406\n",
      "Epoch: 061, Loss: 0.15895\n",
      "Epoch: 062, Loss: 0.15993\n",
      "Epoch: 063, Loss: 0.16011\n",
      "Epoch: 064, Loss: 0.16023\n",
      "Epoch: 065, Loss: 0.15016\n",
      "Epoch: 066, Loss: 0.15184\n",
      "Epoch: 067, Loss: 0.15090\n",
      "Epoch: 068, Loss: 0.15936\n",
      "Epoch: 069, Loss: 0.14929\n",
      "Epoch: 070, Loss: 0.15163\n",
      "Epoch: 071, Loss: 0.17315\n",
      "Epoch: 072, Loss: 0.14997\n",
      "Epoch: 073, Loss: 0.15424\n",
      "Epoch: 074, Loss: 0.17443\n",
      "Epoch: 075, Loss: 0.14901\n",
      "Epoch: 076, Loss: 0.15244\n",
      "Epoch: 077, Loss: 0.17633\n",
      "Epoch: 078, Loss: 0.15613\n",
      "Epoch: 079, Loss: 0.15750\n",
      "Epoch: 080, Loss: 0.15821\n",
      "Epoch: 081, Loss: 0.15882\n",
      "Epoch: 082, Loss: 0.15948\n",
      "Epoch: 083, Loss: 0.15246\n",
      "Epoch: 084, Loss: 0.17264\n",
      "Epoch: 085, Loss: 0.15475\n",
      "Epoch: 086, Loss: 0.15519\n",
      "Epoch: 087, Loss: 0.16079\n",
      "Epoch: 088, Loss: 0.16145\n",
      "Epoch: 089, Loss: 0.14929\n",
      "Epoch: 090, Loss: 0.15033\n",
      "Epoch: 091, Loss: 0.17004\n",
      "Epoch: 092, Loss: 0.14897\n",
      "Epoch: 093, Loss: 0.15181\n",
      "Epoch: 094, Loss: 0.15428\n",
      "Epoch: 095, Loss: 0.17550\n",
      "Epoch: 096, Loss: 0.14950\n",
      "Epoch: 097, Loss: 0.15235\n",
      "Epoch: 098, Loss: 0.14898\n",
      "Epoch: 099, Loss: 0.17775\n",
      "Test Accuracy: 0.9269\n"
     ]
    }
   ],
   "source": [
    "def test_1layer_GConvLSTM(df):\n",
    "    x = np.zeros([df.shape[0], 3, 2])\n",
    "    x[:, 0, 0] = df['Prcp1'].values\n",
    "    x[:, 0, 1] = df['SM1'].values\n",
    "    x[:, 1, 0] = df['Prcp2'].values\n",
    "    x[:, 1, 1] = df['SM2'].values\n",
    "    x[:, 2, 0] = df['Prcp3'].values\n",
    "    x[:, 2, 1] = df['SM3'].values\n",
    "\n",
    "    y = np.zeros([df.shape[0], 3, 1])\n",
    "    y[:, 0, 0] = df['flood1'].values\n",
    "    y[:, 1, 0] = df['flood2'].values\n",
    "    y[:, 2, 0] = df['flood3'].values\n",
    "\n",
    "    dataset = StaticGraphTemporalSignal(\n",
    "        edge_index = np.array([[0, 2], [1, 1]], dtype=np.compat.long),\n",
    "        edge_weight = np.array([1.0, 1.0], dtype=float),\n",
    "        features = x,\n",
    "        targets = y\n",
    "    )\n",
    "\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "\n",
    "    class TemporalGNN(torch.nn.Module):\n",
    "        def __init__(self, dim_in):\n",
    "            super().__init__()\n",
    "            self.recurrent = GConvLSTM(dim_in, 16, 1)\n",
    "            self.linear = Linear(16, 1)\n",
    "\n",
    "        def forward(self, x, edge_index, edge_weight):\n",
    "            x, _ = self.recurrent(x, edge_index, edge_weight)\n",
    "            x = x.relu()\n",
    "            x = self.linear(x)\n",
    "            return x.sigmoid()\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model = TemporalGNN(dim_in=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(100):\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            snapshot.to(device)\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "            cost = criterion(y_hat, snapshot.y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, cost.item()))\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        snapshot.to(device)\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_weight)\n",
    "        y_pred.append(y_hat.detach().cpu().numpy())\n",
    "        y_true.append(snapshot.y.detach().cpu().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    print('Test Accuracy: {:.4f}'.format((y_pred.round() == y_true).mean()))\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "test_1layer_GConvLSTM(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d952b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
